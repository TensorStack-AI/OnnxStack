{
    "input_model": {
        "type": "PyTorchModel",
        "config": {
            "model_path": "M:\\BaseModels\\CogVideoX-2B",
            "model_loader": "vae_decoder_load",
            "model_script": "models.py",
            "io_config": {
                "input_names": [ "latent_sample" ],
                "output_names": [ "sample" ],
                "dynamic_axes": { "latent_sample": { "0": "batch", "1": "channels", "2": "frames", "3": "height", "4": "width" } }
            },
            "dummy_inputs_func": "vae_decoder_conversion_inputs"
        }
    },
    "systems": {
        "local_system": {
            "type": "LocalSystem",
            "config": {
                "accelerators": [
                    {
                        "device": "gpu",
                        "execution_providers": [
                            "CPUExecutionProvider",
                            "DmlExecutionProvider"
                        ]
                    }
                ]
            }
        }
    },
    "passes": {
        "convert": {
            "type": "OnnxConversion",
            "config": {
                "target_opset": 20,
                "save_as_external_data": true,
                "all_tensors_to_one_file": true
            }
        },
        "optimize": {
            "type": "OrtTransformersOptimization",
            "config": {
                "model_type": "vae",
                "opt_level": 0,
                "float16": true,
                "use_gpu": true,
                "keep_io_types": false
            }
        }
    },
    "pass_flows": [
        ["convert", "optimize"]
    ],
    "engine": {
        "log_severity_level": 0,
        "evaluate_input_model": false,
        "host": "local_system",
        "target": "local_system",
        "cache_dir": "cache",
        "output_name": "vae_decoder",
        "output_dir": "footprints"
    }
}
